{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9a1AD2pD6jyUMnwP2QXbt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThasanickaSivapragasam/AI-mini-project/blob/main/MiniProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "huSiMBDnJ-1v",
        "outputId": "f1a11ef2-ec04-4968-9bd1-b3bb8ee00725"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 67)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m67\u001b[0m\n\u001b[0;31m    def preprocess_data(self, X, y=None, fit_scaler=False):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "# EventRecommenderNN class\n",
        "class EventRecommenderNN:\n",
        "    def __init__(self, input_dim=8, num_categories=8):\n",
        "        \"\"\"\n",
        "        Neural Network for Event Recommendation System\n",
        "        Args:\n",
        "            input_dim: Number of input features (8 event category scores)\n",
        "            num_categories: Number of event categories to predict (8)\n",
        "        \"\"\"\n",
        "        self.input_dim = input_dim\n",
        "        self.num_categories = num_categories\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.event_categories = [\n",
        "            'Programming & Coding', 'Entrepreneurship', 'Career Guidance',\n",
        "            'Leadership & Communication', 'Volunteering', 'Mental Health',\n",
        "            'Arts & Culture', 'Subject-Specific'\n",
        "        ]\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"\n",
        "        Build the neural network architecture\n",
        "        \"\"\"\n",
        "\n",
        "        #Layer 1: Dense 128 + BatchNorm + Dropout(0.3)\n",
        "        inputs = Input(shape=(self.input_dim,), name='student_preferences')\n",
        "        x = Dense(128, activation='relu')(inputs)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        # Layer 2: Dense 64 + BatchNorm + Dropout(0.2)\n",
        "        x = Dense(64, activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "        # Layer 3: Dense 32 + BatchNorm + Dropout(0.1)\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.1)(x)\n",
        "\n",
        "        #Output layer: 8 categories with softmax for probability distribution\n",
        "        outputs = Dense(self.num_categories, activation='softmax', name='event_choice')(x)\n",
        "\n",
        "        #Build & compile model\n",
        "        self.model = Model(inputs=inputs, outputs=outputs)\n",
        "        self.model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),  # Adam optimizer with lr=0.001\n",
        "            loss=SparseCategoricalCrossentropy(), # Multi-class classification loss\n",
        "            metrics=[SparseCategoricalAccuracy()] # Accuracy metric\n",
        "        )\n",
        "        return self.model\n",
        "\n",
        "    def preprocess_data(self, X, y=None, fit_scaler=False):\n",
        "        \"\"\"\n",
        "        Preprocess the input data\n",
        "        \"\"\"\n",
        "        if fit_scaler:\n",
        "            X_scaled = self.scaler.fit_transform(X) # Fit scaler on training data\n",
        "        else:\n",
        "            X_scaled = self.scaler.transform(X) # Use previously fitted scaler\n",
        "\n",
        "        if y is not None:\n",
        "            return X_scaled, y\n",
        "        return X_scaled\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, epochs=200, batch_size=32):\n",
        "        \"\"\"\n",
        "        Train the model\n",
        "        \"\"\"\n",
        "\n",
        "        # Scale training and validation data\n",
        "        X_train_scaled, y_train = self.preprocess_data(X_train, y_train, fit_scaler=True)\n",
        "        X_val_scaled, y_val = self.preprocess_data(X_val, y_val)\n",
        "\n",
        "\n",
        "        # Callbacks: Stop training early + Reduce learning rate when stuck\n",
        "        callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-6)\n",
        "        ]\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(\n",
        "            X_train_scaled, y_train,\n",
        "            validation_data=(X_val_scaled, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        return history\n",
        "\n",
        "\n",
        "# Plot training curves\n",
        "\n",
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "   # Training vs Validation Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2, linestyle='--')\n",
        "    plt.title('üìâ Model Loss Over Time', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Training vs Validation Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['sparse_categorical_accuracy'], label='Training Accuracy', linewidth=2)\n",
        "    plt.plot(history.history['val_sparse_categorical_accuracy'], label='Validation Accuracy', linewidth=2, linestyle='--')\n",
        "    plt.title('üéØ Model Accuracy Over Time', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Load data for training\n",
        "def load_data_for_training():\n",
        "    \"\"\"\n",
        "    Load training and validation data from CSV files\n",
        "    \"\"\"\n",
        "    try:\n",
        "        X_train = pd.read_csv('X_train.csv').values\n",
        "        y_train = pd.read_csv('y_train.csv').values[:, 0].ravel() # Select the first column before flattening\n",
        "        X_val = pd.read_csv('X_val.csv').values\n",
        "        y_val = pd.read_csv('y_val.csv').values[:, 0].ravel() # Select the first column before flattening\n",
        "        print(f\"‚úÖ Training set: {X_train.shape[0]} samples\")\n",
        "        print(f\"‚úÖ Validation set: {X_val.shape[0]} samples\")\n",
        "        return X_train, y_train, X_val, y_val\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading training data: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# Load data for evaluation\n",
        "# Load Test Data\n",
        "\n",
        "def load_data_for_evaluation():\n",
        "    \"\"\"\n",
        "    Load test data from CSV files\n",
        "    \"\"\"\n",
        "    try:\n",
        "        X_test = pd.read_csv('X_test.csv').values\n",
        "        y_test = pd.read_csv('y_test.csv').values[:, 0].ravel() # Select the first column before flattening\n",
        "        print(f\"\\n‚úÖ Test set: {X_test.shape[0]} samples\")\n",
        "        return X_test, y_test\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading test data: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# Evaluate model performance\n",
        "def evaluate_model(recommender, X_test, y_test):\n",
        "    print(\"\\nüìä Evaluating Model...\")\n",
        "    try:\n",
        "        # Scale test features\n",
        "        X_test_scaled = recommender.preprocess_data(X_test) # No need to pass y_test for scaling\n",
        "\n",
        "        # Compute loss and accuracy\n",
        "        loss, acc = recommender.model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "\n",
        "        # Get Predictions\n",
        "        predictions = recommender.model.predict(X_test_scaled, verbose=0)\n",
        "        pred_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Top-1 Accuracy\n",
        "        top1_acc = np.mean(y_test == pred_classes)\n",
        "\n",
        "        # Top-3 Accuracy\n",
        "        top3_preds = np.argsort(predictions, axis=1)[:, -3:]\n",
        "        top3_acc = np.mean([y_test[i] in top3_preds[i] for i in range(len(y_test))])\n",
        "\n",
        "        # Classification Report/ report\n",
        "        report = classification_report(y_test, pred_classes, output_dict=True)\n",
        "        f1_macro = report['macro avg']['f1-score']\n",
        "        f1_weighted = report['weighted avg']['f1-score']\n",
        "        precision_macro = report['macro avg']['precision']\n",
        "        recall_macro = report['macro avg']['recall']\n",
        "\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\nüéØ Evaluation Results:\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"üìà Top-1 Accuracy: {top1_acc:.4f} ({top1_acc*100:.1f}%)\")\n",
        "        print(f\"üèÖ Top-3 Accuracy: {top3_acc:.4f} ({top3_acc*100:.1f}%)\")\n",
        "        print(f\"üìâ Test Loss: {loss:.4f}\")\n",
        "        print(f\"üìä F1 Score (Macro): {f1_macro:.4f}\")\n",
        "        print(f\"üìä F1 Score (Weighted): {f1_weighted:.4f}\")\n",
        "        print(f\"üìä Precision (Macro): {precision_macro:.4f}\")\n",
        "        print(f\"üìä Recall (Macro): {recall_macro:.4f}\")\n",
        "\n",
        "        return top1_acc, top3_acc, loss, f1_macro, f1_weighted, precision_macro, recall_macro\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Evaluation error: {e}\")\n",
        "        return None, None, None, None, None, None, None\n",
        "\n",
        "\n",
        "# Full Training pipeline\n",
        "def train_pipeline():\n",
        "    print(\"üöÄ Starting Event Recommender Training Pipeline\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "        #Load Training Data\n",
        "    try:\n",
        "        X_train, y_train, X_val, y_val = load_data_for_training()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Training aborted: {e}\")\n",
        "        return\n",
        "\n",
        "\n",
        "        #Build Model\n",
        "    print(\"\\nüèó Building Neural Network Model...\")\n",
        "    recommender = EventRecommenderNN(input_dim=8, num_categories=8)\n",
        "    model = recommender.build_model()\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "        # Train Model\n",
        "    print(\"\\nüéØ Training Model...\")\n",
        "    history = recommender.train(X_train, y_train, X_val, y_val)\n",
        "\n",
        "\n",
        "        #Visualize training\n",
        "    print(\"\\nüìà Visualizing Training Progress...\")\n",
        "    plot_training_history(history)\n",
        "\n",
        "\n",
        "\n",
        "        # Save model + scaler\n",
        "    print(\"\\nüíæ Saving trained model and scaler...\")\n",
        "    try:\n",
        "        model.save('event_recommender_model.h5')\n",
        "        joblib.dump(recommender.scaler, 'scaler.pkl')\n",
        "        print(\"‚úÖ Model and scaler saved!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö† Could not save: {e}\")\n",
        "\n",
        "\n",
        "        # Evaluate model\n",
        "    print(\"\\nüîç Evaluating on Test Data...\")\n",
        "    try:\n",
        "        X_test, y_test = load_data_for_evaluation()\n",
        "        evaluate_model(recommender, X_test, y_test)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Evaluation failed: {e}\")\n",
        "\n",
        "    return recommender\n",
        "\n",
        "# Main entry point\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_pipeline()"
      ]
    }
  ]
}